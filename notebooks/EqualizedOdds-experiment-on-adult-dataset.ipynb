{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "from fairlearn.reductions import ExponentiatedGradient\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = shap.datasets.adult()\n",
    "sensitive_attribute = 'Sex'\n",
    "\n",
    "A = X[sensitive_attribute]\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "X = X.reset_index(drop=True)\n",
    "A = A.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeastSquaresBinaryClassifierLearner:\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X, Y, sample_weight):\n",
    "        sqrtW = np.sqrt(sample_weight)\n",
    "        matX = np.array(X) * sqrtW[:, np.newaxis]\n",
    "        vecY = Y * sqrtW\n",
    "        self.lsqinfo = np.linalg.lstsq(matX, vecY, rcond=-1)\n",
    "        self.weights = pd.Series(self.lsqinfo[0], index=list(X))\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = X.dot(np.asarray(self.weights))\n",
    "        return 1 * (pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(y, predicted_y):\n",
    "    correct_y = (y==predicted_y)\n",
    "    return 1 - sum(correct_y)/len(correct_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmitigated_predictor = LeastSquaresBinaryClassifierLearner()\n",
    "unmitigated_predictor.fit(X, Y, sample_weight=[1])\n",
    "\n",
    "unmitigated_y = pd.Series(unmitigated_predictor.predict(X),\n",
    "                          name='unmitigated_predicted_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_unmitigated = [get_error(Y, unmitigated_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EqualizedOdds violation is calculated as:\n",
    "# max(abs(E[h(x)| A = a, Y = y] - E[h(x) | Y = y]))\n",
    "def get_eo_violation(predict_y, A, Y, label_name):\n",
    "    violations = []\n",
    "    predicted_and_y_and_sensitive_feat = pd.concat([predict_y, Y, A],axis=1)\n",
    "    grouped_y_and_sensitive_feat = predicted_and_y_and_sensitive_feat.groupby(\n",
    "        [Y, sensitive_attribute])\n",
    "    pass_by_group = grouped_y_and_sensitive_feat[[label_name]].sum()\n",
    "    counts_by_group = grouped_y_and_sensitive_feat[[label_name]].count()\n",
    "\n",
    "    grouped_y = predicted_and_y_and_sensitive_feat.groupby(Y)\n",
    "    pass_by_y = grouped_y[[label_name]].sum()\n",
    "    counts_by_y = grouped_y[[label_name]].count()\n",
    "\n",
    "    pos_prob = pass_by_y[label_name][1] / counts_by_y[label_name][1]\n",
    "    neg_prob = pass_by_y[label_name][0] / counts_by_y[label_name][0]\n",
    "\n",
    "    for key, item in enumerate(grouped_y_and_sensitive_feat.groups.keys()):\n",
    "        # E[h(x) | Y = y]\n",
    "        if item[0] == 1:\n",
    "            violation_2 = pos_prob\n",
    "        if item[0] == 0:\n",
    "            violation_2 = neg_prob\n",
    "\n",
    "        # E[h(x)| A = a, Y = y]\n",
    "        violation_1 = pass_by_group[label_name][item[0]][item[1]] / \\\n",
    "                     counts_by_group[label_name][item[0]][item[1]]\n",
    "\n",
    "        violations.append(abs(violation_1 - violation_2))\n",
    "\n",
    "    violation = max(violations)\n",
    "    return violation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_Y = pd.Series(Y, name='true_y')\n",
    "eo_violation_unmitigated = [get_eo_violation(unmitigated_y, A, true_Y,\n",
    "                                             'unmitigated_predicted_y')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1 - Calculating violation by varying epsilon \n",
    "from fairlearn.reductions import EqualizedOdds\n",
    "\n",
    "eps_list = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "expgrad_error = []\n",
    "eo_expgrad_violation = []\n",
    "\n",
    "estimator = LeastSquaresBinaryClassifierLearner()\n",
    "\n",
    "for eps in eps_list:\n",
    "    expgrad_X = ExponentiatedGradient(estimator,\n",
    "                                      constraints=EqualizedOdds(),\n",
    "                                      eps=eps, nu=1e-6)\n",
    "    \n",
    "    expgrad_X.fit(X, Y, sensitive_features=A)\n",
    "    expgrad_y = pd.Series(expgrad_X.predict(X), name='expgrad_predicted_y')\n",
    "    \n",
    "    error_expgrad = get_error(Y, expgrad_y)\n",
    "    expgrad_error.append(error_expgrad)\n",
    "    \n",
    "    eo_violation_expgrad = get_eo_violation(expgrad_y, A, true_Y,\n",
    "                                            'expgrad_predicted_y')\n",
    "    eo_expgrad_violation.append(eo_violation_expgrad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{}\\t\\t{}\\t\\t\\t{}'.format('Epsilon', 'Max Violation', 'Error'))\n",
    "for i in range(len(eps_list)):\n",
    "    print('{}\\t\\t{}\\t\\t{}'.format(eps_list[i], eo_expgrad_violation[i],\n",
    "                                  expgrad_error[i]))\n",
    "print('{}\\t\\t{}\\t\\t{}'.format('Unmit.', eo_violation_unmitigated[0],\n",
    "                              error_unmitigated[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(eo_expgrad_violation, expgrad_error, label=\"expgrad\")\n",
    "plt.plot(eo_violation_unmitigated, error_unmitigated, 'ro', label=\"unmitigated\")\n",
    "plt.xlabel('Violation of the fairness constraint')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Adult UCI / Equalized Odds / Simple Learner')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EqualizedOdds violation is calculated as:\n",
    "# max(ratio * E[h(x)| A = a, Y = y] - E[h(x) | Y = y]),\n",
    "#     - E[h(x)| A = a, Y = y] + ratio * E[h(x) | Y = y])\n",
    "def get_eo_ratio_violation(predict_y, A, Y, ratio, label_name):\n",
    "    violations = []\n",
    "    predicted_and_y_and_sensitive_feat = pd.concat([predict_y, Y, A], axis=1)\n",
    "    grouped_y_and_sensitive_feat = predicted_and_y_and_sensitive_feat.groupby(\n",
    "        [Y, sensitive_attribute])\n",
    "    pass_by_group = grouped_y_and_sensitive_feat[[label_name]].sum()\n",
    "    counts_by_group = grouped_y_and_sensitive_feat[[label_name]].count()\n",
    "\n",
    "    grouped_y = predicted_and_y_and_sensitive_feat.groupby(Y)\n",
    "    pass_by_y = grouped_y[[label_name]].sum()\n",
    "    counts_by_y = grouped_y[[label_name]].count()\n",
    "\n",
    "    pos_prob = pass_by_y[label_name][1] / counts_by_y[label_name][1]\n",
    "    neg_prob = pass_by_y[label_name][0] / counts_by_y[label_name][0]\n",
    "\n",
    "    for key, item in enumerate(grouped_y_and_sensitive_feat.groups.keys()):\n",
    "        # E[h(x) | Y = y]\n",
    "        if item[0] == 1:\n",
    "            violation_2 = pos_prob\n",
    "        if item[0] == 0:\n",
    "            violation_2 = neg_prob\n",
    "\n",
    "        # E[h(x)| A = a, Y = y]\n",
    "        violation_1 = pass_by_group[label_name][item[0]][item[1]] / \\\n",
    "                     counts_by_group[label_name][item[0]][item[1]]\n",
    "\n",
    "        violations.append((ratio * violation_1) - violation_2)\n",
    "        violations.append(- violation_1 + (ratio * violation_2))\n",
    "\n",
    "    violation = max(violations)\n",
    "    return violation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2 - Calculating violation by varying epsilon \n",
    "from fairlearn.reductions import EqualizedOdds\n",
    "\n",
    "ratio_list = [0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "eps_list = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "ratio_to_violation = {}\n",
    "ratio_to_error = {}\n",
    "ratio_to_unmitigated_eo_violation = {}\n",
    "\n",
    "for ratio in ratio_list:\n",
    "    expgrad_error = []\n",
    "    eo_expgrad_violation = []\n",
    "    estimator = LeastSquaresBinaryClassifierLearner()\n",
    "\n",
    "    for eps in eps_list:\n",
    "        expgrad_X = ExponentiatedGradient(estimator,\n",
    "                                          constraints=EqualizedOdds(),\n",
    "                                          eps=eps, nu=1e-6)\n",
    "\n",
    "        expgrad_X.fit(X, Y, sensitive_features=A)\n",
    "        expgrad_y = pd.Series(expgrad_X.predict(X), name='expgrad_predicted_y')\n",
    "\n",
    "        error_expgrad = get_error(Y, expgrad_y)\n",
    "        expgrad_error.append(error_expgrad)\n",
    "\n",
    "        eo_violation_expgrad = get_eo_ratio_violation(expgrad_y, A, true_Y, ratio,\n",
    "                                                      'expgrad_predicted_y')\n",
    "        eo_expgrad_violation.append(eo_violation_expgrad)\n",
    "    \n",
    "    ratio_to_violation[ratio] = eo_expgrad_violation\n",
    "    ratio_to_error[ratio] = expgrad_error\n",
    "    \n",
    "    eo_violation_unmitigated = get_eo_ratio_violation(unmitigated_y, A, true_Y,\n",
    "                                                      ratio,\n",
    "                                                      'unmitigated_predicted_y')\n",
    "    ratio_to_unmitigated_eo_violation[ratio] = eo_violation_unmitigated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ratio in ratio_list:\n",
    "    print('Ratio: {}'.format(ratio))\n",
    "    eo_expgrad_violation = ratio_to_violation[ratio]\n",
    "    expgrad_error = ratio_to_error[ratio]\n",
    "    print('{}\\t\\t{}\\t\\t\\t{}'.format('Epsilon', 'Max Violation', 'Error'))\n",
    "    for i in range(len(eps_list)):\n",
    "        print('{}\\t\\t{}\\t\\t{}'.format(eps_list[i], eo_expgrad_violation[i],\n",
    "                                      expgrad_error[i]))\n",
    "    print('{}\\t\\t{}\\t\\t{}'.format('Unmit.', ratio_to_unmitigated_eo_violation[ratio],\n",
    "                                  error_unmitigated[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for ratio in ratio_list:\n",
    "    eo_expgrad_violation = ratio_to_violation[ratio]\n",
    "    expgrad_error = ratio_to_error[ratio]\n",
    "    \n",
    "    plt.scatter(eo_expgrad_violation, expgrad_error, label=\"expgrad\")\n",
    "    plt.plot([ratio_to_unmitigated_eo_violation[ratio]], error_unmitigated, 'ro', label=\"unmitigated\")\n",
    "    plt.xlabel('Violation of the fairness constraint')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('Adult UCI / Equalized Odds Ratio = {} / Simple Learner'.format(ratio))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
